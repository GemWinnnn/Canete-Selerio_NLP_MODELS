{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea83c31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\canet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Markov Chain Prediction ===\n",
      "Sample prediction: I like to talk to matters of\n",
      "Markov Chain Accuracy: 30.60%\n",
      "\n",
      "=== LSTM Prediction ===\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 98\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== LSTM Prediction ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     97\u001b[39m lstm = LSTMTextPredictor()\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m lstm_accuracy = \u001b[43mlstm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSample prediction:\u001b[39m\u001b[33m\"\u001b[39m, lstm.predict(\u001b[33m\"\u001b[39m\u001b[33mI like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m    100\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLSTM Training Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlstm_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mLSTMTextPredictor.train\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     66\u001b[39m     tokens = \u001b[38;5;28mself\u001b[39m.tokenizer.texts_to_sequences([line])[\u001b[32m0\u001b[39m]\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tokens)):\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         seq = \u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     69\u001b[39m         sequences.append(seq)\n\u001b[32m     70\u001b[39m sequences = pad_sequences(sequences, maxlen=\u001b[38;5;28mself\u001b[39m.max_len, padding=\u001b[33m'\u001b[39m\u001b[33mpre\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mMemoryError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# text_prediction.py\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "# ---------- Traditional ML: Markov Chain (n-gram) ----------\n",
    "class MarkovChainPredictor:\n",
    "    def __init__(self, n=2):\n",
    "        self.n = n\n",
    "        self.model = defaultdict(list)\n",
    "\n",
    "    def train(self, text):\n",
    "        tokens = text.split()\n",
    "        for i in range(len(tokens) - self.n):\n",
    "            key = tuple(tokens[i:i+self.n])\n",
    "            self.model[key].append(tokens[i+self.n])\n",
    "        return tokens  # Return tokens for evaluation\n",
    "\n",
    "    def predict(self, seed_text, num_words=10):\n",
    "        tokens = seed_text.split()\n",
    "        result = tokens[:]\n",
    "        for _ in range(num_words):\n",
    "            key = tuple(result[-self.n:])\n",
    "            next_word = random.choice(self.model.get(key, [\"\"]))\n",
    "            result.append(next_word)\n",
    "        return \" \".join(result)\n",
    "\n",
    "    def evaluate_accuracy(self, tokens, num_predictions=1000):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i in range(min(num_predictions, len(tokens) - self.n)):\n",
    "            key = tuple(tokens[i:i+self.n])\n",
    "            actual_next = tokens[i+self.n]\n",
    "            predicted_next = random.choice(self.model.get(key, [\"\"]))\n",
    "            if predicted_next == actual_next:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        return correct / total if total > 0 else 0\n",
    "\n",
    "# ---------- Deep Learning: LSTM ----------\n",
    "class LSTMTextPredictor:\n",
    "    def __init__(self, vocab_size=10000, max_len=20):\n",
    "        self.tokenizer = Tokenizer(num_words=vocab_size)\n",
    "        self.max_len = max_len\n",
    "        self.model = Sequential([\n",
    "            Embedding(vocab_size, 128),\n",
    "            LSTM(128),\n",
    "            Dense(vocab_size, activation='softmax')\n",
    "        ])\n",
    "        self.model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    def train(self, text):\n",
    "        lines = text.split('\\n')\n",
    "        self.tokenizer.fit_on_texts(lines)\n",
    "        sequences = []\n",
    "        for line in lines:\n",
    "            tokens = self.tokenizer.texts_to_sequences([line])[0]\n",
    "            for i in range(1, len(tokens)):\n",
    "                seq = tokens[:i+1]\n",
    "                sequences.append(seq)\n",
    "        sequences = pad_sequences(sequences, maxlen=self.max_len, padding='pre')\n",
    "        X, y = sequences[:, :-1], sequences[:, -1]\n",
    "        history = self.model.fit(X, y, epochs=5, verbose=0)\n",
    "        return history.history['accuracy'][-1]  # Return final training accuracy\n",
    "\n",
    "    def predict(self, seed_text, num_words=10):\n",
    "        for _ in range(num_words):\n",
    "            token_seq = self.tokenizer.texts_to_sequences([seed_text])[0]\n",
    "            token_seq = pad_sequences([token_seq], maxlen=self.max_len-1, padding='pre')\n",
    "            pred_id = np.argmax(self.model.predict(token_seq, verbose=0))\n",
    "            word = self.tokenizer.index_word.get(pred_id, \"\")\n",
    "            seed_text += ' ' + word\n",
    "        return seed_text\n",
    "\n",
    "# ---------- Test ----------\n",
    "if __name__ == \"__main__\":\n",
    "    # Use a subset of the Gutenberg corpus as training data\n",
    "    # Get a list of all available books\n",
    "    book_ids = gutenberg.fileids()\n",
    "    # Use just one book for training (e.g., 'austen-emma.txt')\n",
    "    sample_text = ' '.join(gutenberg.words('austen-emma.txt'))\n",
    "    \n",
    "    print(\"=== Markov Chain Prediction ===\")\n",
    "    mc = MarkovChainPredictor(n=2)\n",
    "    tokens = mc.train(sample_text)\n",
    "    print(\"Sample prediction:\", mc.predict(\"I like\", 5))\n",
    "    mc_accuracy = mc.evaluate_accuracy(tokens)\n",
    "    print(f\"Markov Chain Accuracy: {mc_accuracy:.2%}\")\n",
    "    \n",
    "    print(\"\\n=== LSTM Prediction ===\")\n",
    "    lstm = LSTMTextPredictor(vocab_size=5000, max_len=10)  # Reduced vocab size and sequence length\n",
    "    lstm_accuracy = lstm.train(sample_text)\n",
    "    print(\"Sample prediction:\", lstm.predict(\"I like\", 5))\n",
    "    print(f\"LSTM Training Accuracy: {lstm_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54344059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\canet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes Classification ===\n",
      "Accuracy: 81.50%\n",
      "'I really liked this movie' -> Negative\n",
      "'This was the worst experience' -> Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\canet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# sentiment_classification.py\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "# Sample data\n",
    "texts = [' '.join(movie_reviews.words(fileid)) for fileid in movie_reviews.fileids()]\n",
    "labels = [1 if fileid.startswith('pos') else 0 for fileid in movie_reviews.fileids()]\n",
    "\n",
    "test_samples = [\"I really liked this movie\", \"This was the worst experience\"]\n",
    "\n",
    "# ---------- Traditional ML: Naive Bayes ----------\n",
    "def traditional_sentiment_classification():\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "    print(\"=== Naive Bayes Classification ===\")\n",
    "    print(f\"Accuracy: {acc:.2%}\")\n",
    "\n",
    "    test_vec = vectorizer.transform(test_samples)\n",
    "    test_preds = model.predict(test_vec)\n",
    "    for text, label in zip(test_samples, test_preds):\n",
    "        print(f\"'{text}' -> {'Positive' if label == 1 else 'Negative'}\")\n",
    "\n",
    "# ---------- Deep Learning: LSTM ----------\n",
    "def deep_sentiment_classification():\n",
    "    tokenizer = Tokenizer(num_words=1000)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    X = tokenizer.texts_to_sequences(texts)\n",
    "    X = pad_sequences(X, maxlen=10)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=1000, output_dim=64, input_length=10),\n",
    "        LSTM(64),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history = model.fit(X, y, epochs=10, verbose=0)\n",
    "\n",
    "    test_seq = tokenizer.texts_to_sequences(test_samples)\n",
    "    test_seq = pad_sequences(test_seq, maxlen=10)\n",
    "    predictions = model.predict(test_seq)\n",
    "\n",
    "    print(\"\\n=== LSTM Sentiment Predictions ===\")\n",
    "    for text, pred in zip(test_samples, predictions):\n",
    "        print(f\"'{text}' -> {'Positive' if pred[0] > 0.5 else 'Negative'}\")\n",
    "\n",
    "    # Evaluate the LSTM model on the test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    lstm_acc = model.evaluate(X_test, y_test)[1]\n",
    "    print(f\"LSTM Accuracy: {lstm_acc:.2%}\")\n",
    "\n",
    "# ---------- Run Both ----------\n",
    "if __name__ == \"__main__\":\n",
    "    traditional_sentiment_classification()\n",
    "    deep_sentiment_classification()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
